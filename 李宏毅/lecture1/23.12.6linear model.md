如何通过一张图片识别出一只猫：让机器寻找一个复杂的函数

regression

classification:例如alpha go

structured learning:有结构的，文章，生成图片

regression:youtube依据过去数据推测未来

1.先写一个预测函数（建立一个model）

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206224337656.png" alt="image-20231206224337656" style="zoom:67%;" />

2.loss函数：lable正确的数值

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206224655787.png" alt="image-20231206224655787" style="zoom:67%;" />

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206224826980.png" alt="image-20231206224826980" style="zoom:67%;" />

error surface<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206225034053.png" alt="image-20231206225034053" style="zoom:67%;" />

3.optimization：选取最佳方案

单个参数

真的无法找到真正的最优解？

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206230450826.png" alt="image-20231206230450826" style="zoom:67%;" />

多元这样求真得合理吗

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206230745233.png" alt="image-20231206230745233" style="zoom:67%;" />

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206230916218.png" alt="image-20231206230916218" style="zoom:67%;" />

最后一步：通过实际数据验证

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206231250868.png" alt="image-20231206231250868" style="zoom:67%;" />

总结：何为linear model

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231206232015106.png" alt="image-20231206232015106" style="zoom:67%;" />





线性可能无法真实反映二者关系：存在model bias

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207155015693.png" alt="image-20231207155015693" style="zoom:67%;" />

如何解决线性的缺陷呢：化曲为直，“微分思想”

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207160008654.png" alt="image-20231207160008654" style="zoom:67%;" />

sigmoid function

作用：“拟合”，就像一个大的积木是由一个一个小块组成的

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207160444985.png" alt="image-20231207160444985" style="zoom:67%;" />

非常具有弹性

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207161230831.png" alt="image-20231207161230831" style="zoom:67%;" />

模型的不断优化：不仅具有弹性，而且还有“远见”（不会只盯着前一天）

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207161600702.png" alt="image-20231207161600702" style="zoom:67%;" />

神经网络？！

一层一层最终得到结果

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207162334060.png" alt="image-20231207162334060" style="zoom:67%;" />

终于找到线性代数的应用了！！

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207162403901.png" alt="image-20231207162403901" style="zoom:67%;" />

简洁之美！！

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207162606994.png" alt="image-20231207162606994" style="zoom:67%;" />

Loss再相遇：由于未知量的增加，统一用L（θ）表示

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207163306230.png" alt="image-20231207163306230" style="zoom:67%;" />

optimazation的再相遇

要点：θ*，复杂表达表达式的简写

再回到线性代数的本质：不过是一门工具，更方便的处理大量的数据

![image-20231207163642124](C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207163642124.png)

反复迭代

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207163859722.png" alt="image-20231207163859722" style="zoom:67%;" />

CPU AND GPU

大数据由于其“大”的特点，因此将N分成一个个B，电脑面对一个个B究竟是并行还是串行，分别对应Gpu和CPU

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207164119231.png" alt="image-20231207164119231" style="zoom:67%;" />

小update 大epoch

人为设定：hyperparameters

sigmoid vs ReLU(activation function激活函数)

**简单性和效率**：由于ReLU函数在正数区间内是线性的，并且在负数区间输出为0，因此它的计算非常简单，这使得网络在训练和操作时更加高效。

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207164747402.png" alt="image-20231207164747402" style="zoom:67%;" />

![image-20231207164808713](C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207164808713.png)

多层神经网络（狂喜）

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207165049951.png" alt="image-20231207165049951" style="zoom:67%;" />

各种概念不过是小trick罢了，把握本质![248BA2B9](C:\Users\叶xz\AppData\Local\Temp\SGPicFaceTpBq\3540\248BA2B9.png)

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207165716646.png" alt="image-20231207165716646" style="zoom:67%;" />

为何是deep learning而不失“fat learning”即多加ReLU

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207170903057.png" alt="image-20231207170903057" style="zoom:67%;" />

过拟合问题

<img src="C:\Users\叶xz\AppData\Roaming\Typora\typora-user-images\image-20231207170103983.png" alt="image-20231207170103983" style="zoom:67%;" />